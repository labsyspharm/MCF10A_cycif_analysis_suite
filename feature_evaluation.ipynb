{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE,RFECV,SelectKBest\n",
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cycifsuite.get_data import read_synapse_file\n",
    "from rfpimp import importances\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(path, fname, ligand_name=None, sample_size=None, excluding_cells=[]):\n",
    "    '''Read data and construct\n",
    "    '''\n",
    "    os.chdir(path)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    x = pd.read_hdf(fname)\n",
    "    zero_std_cols = x.columns[x.std() == 0]\n",
    "    x = x.drop(zero_std_cols, axis=1)\n",
    "    x.loc[:, :] = imputer.fit_transform(x)\n",
    "\n",
    "    # Sampling easier feature selection\n",
    "    if sample_size is not None:\n",
    "        if isinstance(sample_size, float):\n",
    "            sample_size = int(sample_size * x.shape[0])\n",
    "        elif isinstance(sample_size, int):\n",
    "            pass\n",
    "        # get rid of cells not wanted\n",
    "        sample_pool = [k for k in x.index if k not in excluding_cells]\n",
    "        sample_idx = np.random.choice(\n",
    "            x.index, size=sample_size)\n",
    "        x = x.loc[sample_idx]\n",
    "    # make y_vector\n",
    "    y_vector = None\n",
    "    if ligand_name is not None:\n",
    "        y_vector = [ligand_name] * x.shape[0]\n",
    "    return x, y_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Yunguan Wang!\n",
      "\n",
      "['plate_2_txt_features_BMP2.hdf', 'plate_2_txt_features_EGF.hdf', 'plate_2_txt_features_HGF.hdf', 'plate_2_txt_features_IFNG.hdf', 'plate_2_txt_features_OSM.hdf', 'plate_2_txt_features_PBS.hdf', 'plate_2_txt_features_TGFB.hdf', 'plate_6_txt_features_all.hdf', 'plate_6_txt_features_BMP2.hdf', 'plate_6_txt_features_EGF.hdf', 'plate_6_txt_features_HGF.hdf', 'plate_6_txt_features_IFNG.hdf', 'plate_6_txt_features_OSM.hdf', 'plate_6_txt_features_PBS.hdf', 'plate_6_txt_features_TGFB.hdf']\n"
     ]
    }
   ],
   "source": [
    "path = 'd:/data/MCF10A 090718 data/'\n",
    "os.chdir(path)\n",
    "feature_files = [x for x in os.listdir() if '_txt' in x]\n",
    "pooled_metadata = pd.read_csv(read_synapse_file('syn17902177'),index_col=0)\n",
    "print(feature_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting some simple stats on data, e.g., std, cv\n",
    "## Since Anova is fast, ran it on all data instead of sampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and bin the data well-wise\n",
    "### Note: Scaling for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_binned = pd.DataFrame()\n",
    "y = []\n",
    "for fn in feature_files[1:]:\n",
    "    ligand = fn.split('_')[-1][:-4]\n",
    "    _x, _y = data_preprocessing(path,fn,ligand_name=ligand)\n",
    "    cm_cells = [k for k in _x.index if k in pooled_metadata.index]\n",
    "    _x = _x.loc[cm_cells].groupby(pooled_metadata.loc[cm_cells,'Well']).median()\n",
    "    if x_binned.shape[0]==0:\n",
    "        x_binned = _x\n",
    "    else:\n",
    "        cols = [k for k in x_binned.columns if k in _x.columns]\n",
    "        _x = _x[cols]\n",
    "        x_binned = x_binned[cols].append(_x[cols])\n",
    "    y += [ligand]*_x.shape[0]\n",
    "# scaling\n",
    "y_binned = y\n",
    "x_scale = x_binned.copy()\n",
    "x_scale.loc[:,:] = minmax_scale(x_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read full data just for anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame()\n",
    "y = []\n",
    "for fn in feature_files[1:]:\n",
    "    ligand = fn.split('_')[-1][:-4]\n",
    "    _x, _y = data_preprocessing(path,fn,ligand_name=ligand)\n",
    "    if x.shape[0]==0:\n",
    "        x = _x\n",
    "    else:\n",
    "        cols = [k for k in x.columns if k in _x.columns]\n",
    "        x = x[cols].append(_x[cols])\n",
    "    y+=_y\n",
    "x.loc[:,:] = minmax_scale(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1A std histogram and 1B ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anova\n",
    "sk = SelectKBest(k=x.shape[1])\n",
    "sk.fit(x,y)\n",
    "sk_fs = sk.get_support()\n",
    "sk_fs = x.columns[sk_fs]\n",
    "\n",
    "all_features = x.columns\n",
    "_, axes = plt.subplots(ncols=2, figsize=(16,9))\n",
    "axes = axes.ravel()\n",
    "axes[0].hist(x.std(),bins=50, label='All')\n",
    "for feature_type,c in zip(['_txt_','_har_','_int_','mor'],['orange','g','red','purple']):\n",
    "    feature_list = [k for k in all_features if feature_type in k]\n",
    "    axes[0].hist(x[feature_list].std(), bins=50, label=feature_type.replace('_',''),alpha=0.8,color=c)\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_title('Distribution of std across all samples')\n",
    "\n",
    "anova = pd.Series(sk.scores_, index=x.columns)\n",
    "for feature_type,c in zip(['_txt_','_har_','_int_','mor'],['orange','g','red','purple']):\n",
    "    feature_list = [k for k in all_features if feature_type in k]\n",
    "    axes[1].hist(anova[feature_list], bins=50,label=feature_type.replace('_',''),alpha=0.8,color=c)\n",
    "axes[1].legend()\n",
    "# axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "axes[0].set_title('ANOVA F scores across all samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA to test if the centroids are separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pca=PCA(2)\n",
    "pca_x = pca.fit_transform(x_scale)\n",
    "pca_x = pd.DataFrame(pca_x, columns=['pc1','pc2'])\n",
    "pca_x['ligand'] = y_binned\n",
    "sns.scatterplot('pc1','pc2',data=pca_x,hue='ligand')\n",
    "plt.title('All features', fontsize=18)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the previous analysis using each feature category\n",
    "### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature stats\n",
    "all_featuers  = x_scale.columns\n",
    "txt_features = [k for k in all_featuers if '_txt_' in k]\n",
    "har_features = [k for k in all_featuers if '_har_' in k]\n",
    "int_features = [k for k in all_featuers if '_int_' in k]\n",
    "mor_features = [k for k in all_featuers if 'mor' in k]\n",
    "sum_features=0\n",
    "for feature_type in ['_txt_','_har_','_int_','mor']:\n",
    "    feature_list = [k for k in all_featuers if feature_type in k]\n",
    "    num_features = len(feature_list)\n",
    "    print('Number of {} features : {}'.format(feature_type, num_features))\n",
    "    sum_features+=num_features\n",
    "print('Total number of these categories: {} out of total of {}'.format(sum_features, len(all_featuers)))\n",
    "\n",
    "# PCA plots of each feature category\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,12))\n",
    "axes = axes.ravel()\n",
    "i=0\n",
    "for feature_type in ['_txt_','_har_','_int_','mor']:\n",
    "    feature_list = [k for k in all_featuers if feature_type in k]\n",
    "    num_features = len(feature_list)\n",
    "    pca=PCA(2)\n",
    "    pca_x = pca.fit_transform(x_scale[feature_list])\n",
    "    pca_x = pd.DataFrame(pca_x, columns=['pc1','pc2'])\n",
    "    pca_x['ligand'] = sorted(y_binned)\n",
    "    g = sns.scatterplot('pc1','pc2',data=pca_x,hue='ligand', ax = axes[i])\n",
    "    if i==0:\n",
    "        lgd_handles, lgd_labels = g.get_legend_handles_labels()\n",
    "    g.set_title('{} : {}'.format(feature_type,num_features), fontsize=18)\n",
    "    g.legend('')\n",
    "    pc1 = pca.explained_variance_ratio_[0]\n",
    "    pc2 = pca.explained_variance_ratio_[1]\n",
    "    g.set_xlabel('PC1 explained variance ratio {:.2f}'.format(pc1))\n",
    "    g.set_ylabel('PC2 explained variance ratio {:.2f}'.format(pc2))\n",
    "    i+=1\n",
    "fig.legend(lgd_handles, lgd_labels,loc='center right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate full model and models with different cat of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame()\n",
    "y = []\n",
    "for fn in feature_files[1:]:\n",
    "    ligand = fn.split('_')[-1][:-4]\n",
    "    _x, _y = data_preprocessing(path,fn,ligand_name=ligand, sample_size=1500)\n",
    "    if x.shape[0]==0:\n",
    "        x = _x\n",
    "    else:\n",
    "        cols = [k for k in x.columns if k in _x.columns]\n",
    "        x = x[cols].append(_x[cols])\n",
    "    y+=_y\n",
    "x.loc[:,:] = minmax_scale(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20)\n",
    "print(x_train.shape)\n",
    "full_model = RandomForestClassifier(100)\n",
    "full_model.fit(x_train, y_train)\n",
    "y_pred = full_model.predict(x_test)\n",
    "print('Full feature accuracy {}'.format(acc(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = RandomForestClassifier(100)\n",
    "model_stats = pd.DataFrame()\n",
    "for feature_type in ['_txt_','_har_','_int_','mor','int_old']:\n",
    "    if feature_type == 'int_old':\n",
    "        feature_list = [k for k in all_featuers if '_int_' in k]\n",
    "        feature_list = [k for k in feature_list if k.split('_')[-1] in ['nuc','cyto']]\n",
    "    else:\n",
    "        feature_list = [k for k in all_featuers if feature_type in k]\n",
    "    rf_cv = cross_val_score(cat_model, x_train[feature_list], y_train,scoring='accuracy', cv=10,n_jobs=4)\n",
    "    model_stats.loc['mean',feature_type] = rf_cv.mean()\n",
    "    model_stats.loc['sd',feature_type] = rf_cv.std()\n",
    "    print('CV accurary with feature category {}: {:.2f}'.format(feature_type, rf_cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats.transpose().plot(kind='bar',yerr='sd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is now very clear the morphology features performs terribly on their own.\n",
    "### Why they looked so good on PCA plot? \n",
    "### Remember the assumption before doing binning based PCA, which is high hemogeneity in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the single cell level data on morphology feature. (10% sampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(2)\n",
    "pca_x = pca.fit_transform(x_train[feature_list])\n",
    "pca_x = pd.DataFrame(pca_x, columns=['pc1','pc2'])\n",
    "pca_x['ligand'] = y_train\n",
    "sns.scatterplot('pc1','pc2',data=pca_x,hue='ligand')\n",
    "plt.title('10 morphology feature', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
