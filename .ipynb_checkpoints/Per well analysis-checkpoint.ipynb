{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import synapseclient as syn\n",
    "import synapseutils\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.stats.multitest import fdrcorrection as fdr\n",
    "from matplotlib import pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "sys.path.insert(0, '../../cycif/')\n",
    "from get_data import file2frame\n",
    "from cycif import *\n",
    "from common_apis import *\n",
    "\n",
    "import random\n",
    "random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_log_transform(df_data):\n",
    "    # setting a size threshold for cell size to get rid of doublets\n",
    "    area_cols = [x for x in df_data.columns if 'Area' in x]\n",
    "    invalid_cells = []\n",
    "    for area_col in area_cols:\n",
    "        cell_size_threshold_upper = df_data[area_col].median() + 4*df_data[area_col].std()\n",
    "        invalid_cells += df_data[df_data[area_col]>cell_size_threshold_upper].index.tolist()\n",
    "    invalid_cells = list(set(invalid_cells))\n",
    "    df_data = df_data.drop(invalid_cells)\n",
    "    df_data = df_data.iloc[:,4:]\n",
    "    df_data = np.log2(df_data+1)\n",
    "    return df_data, invalid_cells\n",
    "\n",
    "def plot_clustering(df_low_dim, df_labels, figname = None):\n",
    "    \"\"\"\n",
    "    Make scatter plots of dimention reduced data with cluster designation\n",
    "    \"\"\"\n",
    "    plt.ioff()\n",
    "    df_labels = df_labels.reset_index()\n",
    "    for cluster in sorted(df_labels.iloc[:,1].unique()):\n",
    "        cells_idx = df_labels[df_labels.iloc[:,1]==cluster].index.values\n",
    "        plt.scatter(df_low_dim[cells_idx,0],df_low_dim[cells_idx,1],label=cluster, s = 1)\n",
    "    \n",
    "    plt.legend(markerscale=5,bbox_to_anchor=(1, 0.9))\n",
    "    if figname is None:\n",
    "        plt.savefig('Clustering_on_2D.png',bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(figname,bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def differential_analysis(test_norm, control_norm):\n",
    "    '''\n",
    "    calculated fold change on log transformed data.\n",
    "    ========\n",
    "    Paremeters:\n",
    "    test_norm: pandas.dataframe, a dataframe of normalized test data, rows as cells and columns as features.\n",
    "    control_norm: pandas.dataframe, a dataframe of normalized control data, rows as cells and columns as features.\n",
    "    '''\n",
    "    report = pd.DataFrame(columns=['logFC', 'T_pValue','KS_pValue', 'adj_T_pVal', 'adj_KS_pVal'])\n",
    "    for feature in control_norm.columns:\n",
    "        fc = test_norm[feature].mean() - control_norm[feature].mean()\n",
    "        pval = ttest(control_norm[feature],test_norm[feature])\n",
    "        ks_pval = ks_2samp(control_norm[feature],test_norm[feature])[1]\n",
    "        report.loc[feature,'logFC'] = np.round(fc,2)\n",
    "        report.loc[feature,'T_pValue'] = pval[1]\n",
    "        report.loc[feature,'KS_pValue'] = ks_pval\n",
    "    report['adj_T_pVal'] = fdr(report.T_pValue)[1]\n",
    "    report['adj_KS_pVal'] = fdr(report.KS_pValue)[1]\n",
    "    return report\n",
    "\n",
    "def cluster_based_DE(test_norm, control_norm, figname):\n",
    "    data_umap = umap.fit_transform(test_norm)\n",
    "    labels = clustering_function.fit_predict(data_umap)\n",
    "    labels = pd.Series(['Cluster ' + str(x) for x in labels],index=test_norm.index)\n",
    "    overall_report = pd.DataFrame()\n",
    "    for cluster in labels.unique():\n",
    "        if cluster == 'Cluster -1':\n",
    "            continue\n",
    "        current_cluster_cells = labels[labels==cluster].index\n",
    "        if len(current_cluster_cells) <= 0.01*len(test_norm):\n",
    "            continue\n",
    "        print('\\tPerforming differential analsis on {} which has {} cells'.format(cluster, str(len(current_cluster_cells))))\n",
    "        test_current_cluster = test_norm.loc[current_cluster_cells]\n",
    "        report_current_cluster = differential_analysis(test_current_cluster,control_norm)\n",
    "        report_current_cluster['Cluster'] = cluster\n",
    "        overall_report = overall_report.append(report_current_cluster)\n",
    "    plot_clustering(data_umap,labels,figname)\n",
    "    return overall_report, labels\n",
    "\n",
    "def plot_expr_on_2D(df_2d,df_raw_expr,figname,labels):\n",
    "    \"\"\"\n",
    "    Make a grid of scatter plots of original data projected to a 2D space determined by UMAP.\n",
    "    Each marker is visualized in a subplot and each point in the subplot is colored based on its original expression. \n",
    "    \"\"\"\n",
    "    plt.ioff()\n",
    "    nrows = int(np.ceil(1+len(df_raw_expr.columns)/5))\n",
    "    fig, ax = plt.subplots(nrows, 5, sharex='col', sharey='row',squeeze=False,figsize=(25,5*nrows))\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    # plot control vs test\n",
    "    labels.index = list(range(len(labels)))\n",
    "    for label in labels.unique():\n",
    "        idx = labels[labels==label].index\n",
    "        ax[0].scatter(df_2d[idx,0],df_2d[idx,1], cmap='bwr',s = 1,label = label)\n",
    "    ax[0].legend(markerscale=5, frameon=False)\n",
    "    \n",
    "    # plot markers\n",
    "    idx = 1\n",
    "    for colname in df_raw_expr.columns:\n",
    "        subplot = ax[idx].scatter(df_2d[:,0],df_2d[:,1],c = df_raw_expr[colname].values, s = 1,cmap='bwr',label = colname)\n",
    "        ax[idx].legend(markerscale=5, frameon=False)\n",
    "        fig.colorbar(subplot,ax=[ax[idx],ax[idx]],pad=-0.05,extend='both',format='%.1f')\n",
    "        idx+=1\n",
    "    \n",
    "    plt.savefig(figname,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Yunguan Wang!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "syn = syn.Synapse()\n",
    "syn.login()\n",
    "files = synapseutils.syncFromSynapse(syn, 'syn14734328',path='/data')\n",
    "umap = UMAP(n_neighbors=25)\n",
    "clustering_function = hdbscan.HDBSCAN(min_cluster_size=15,min_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Differential analysis without clustering\n",
    "os.chdir('D:/data/')\n",
    "Report = pd.DataFrame()\n",
    "for time in ['24h','48h','72h']:\n",
    "    for fn in files:\n",
    "        if time in fn.path:\n",
    "            print(fn.path)\n",
    "            data = pd.read_csv(fn.path)\n",
    "            invalid_cols = ['DAPI0002', 'DAPI0003', 'DAPI0004', 'DAPI0005', 'DAPI0006', 'DAPI0007']\n",
    "            data = data.drop(invalid_cols,axis = 1)\n",
    "            data.index = ['Cell_'+str(x) for x in data.index]\n",
    "            metadata = data.iloc[:,:4]\n",
    "            data.columns = [fn.path.split('_')[-1][:-4]+ '_' +x if x not in ['well','DrugName','HMSLid','Conc'] else x for x in data.columns ]\n",
    "            if 'pooled_data' not in globals():\n",
    "                pooled_data = data\n",
    "            else:\n",
    "                pooled_data = pd.concat([pooled_data, data.iloc[:,4:]],axis = 1)\n",
    "    n_control_wells = data[data.DrugName=='DMSO'].well.unique().shape[0]            \n",
    "    pooled_data, invalid_cells = preprocessing_log_transform(pooled_data)\n",
    "    metadata.drop(invalid_cells,inplace=True)\n",
    "\n",
    "    # Get control samples that are from the biggest cluster\n",
    "    controls_cells = metadata[metadata.DrugName=='DMSO'].index\n",
    "    control_norm = pooled_data.loc[controls_cells]\n",
    "#     control_norm_umap = umap.fit_transform(control_norm)\n",
    "#     labels = pd.Series(clustering_function.fit_predict(control_norm_umap),index = controls_cells)\n",
    "#     valid_cluster = labels.value_counts().index[0]\n",
    "#     valid_controls = labels[labels==valid_cluster].index\n",
    "#     control_norm = control_norm.loc[valid_controls]\n",
    "#     metadata.loc[labels.index,'Cluster'] = labels.values\n",
    "#     print('From total {} DMSO cells, {} were selected from the biggest cluster'.format(str(len(controls_cells)),str(len(valid_controls))))\n",
    "\n",
    "    # Get markers for each treated condition\n",
    "    metadata['condition'] = metadata.DrugName + '_' + metadata.Conc.round(6).astype(str)\n",
    "    for condition in metadata.condition.unique():\n",
    "        test_cells = metadata[metadata.condition==condition].index\n",
    "        test_dose = condition.split('_')[1]\n",
    "        test_drug = condition.split('_')[0]\n",
    "        test = pooled_data.loc[test_cells]\n",
    "        fig_name = '_'.join([time, test_drug,str(test_dose),'.png'])\n",
    "        \n",
    "        print('Processing: ', time, condition )\n",
    "        DE_report = differential_analysis(test,control_norm)\n",
    "        DE_report.loc['_CellNumber', 'logFC'] = np.log2(n_control_wells*len(test)/len(control_norm))\n",
    "        DE_report['Dose'] = test_dose\n",
    "        DE_report['DrugName'] = test_drug\n",
    "        DE_report['Abs_logFC'] = abs(DE_report.logFC)\n",
    "        DE_report['Time'] = time\n",
    "        DE_report['Cluster'] = 'Whole well'\n",
    "        \n",
    "        Report = Report.append(DE_report)\n",
    "        \n",
    "    # get rid of old pooled_data\n",
    "    del pooled_data\n",
    "    \n",
    "Report.to_excel('MCF10A commons report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/data/mcf10a_24h_cytosol.csv\n",
      "d:/data/mcf10a_24h_nuclear.csv\n",
      "d:/data/mcf10a_48h_cytosol.csv\n",
      "d:/data/mcf10a_48h_nuclear.csv\n",
      "d:/data/mcf10a_72h_cytosol.csv\n",
      "d:/data/mcf10a_72h_nuclear.csv\n"
     ]
    }
   ],
   "source": [
    "os.chdir('D:/data/')\n",
    "overall_data = pd.DataFrame()\n",
    "metadata = pd.read_csv('MCF10A commons metadata.csv',index_col=0)\n",
    "for time in ['24h','48h','72h']:\n",
    "    for fn in files:\n",
    "        if time in fn.path:\n",
    "            print(fn.path)\n",
    "            data = pd.read_csv(fn.path)\n",
    "            invalid_cols = ['DAPI0002', 'DAPI0003', 'DAPI0004', 'DAPI0005', 'DAPI0006', 'DAPI0007']\n",
    "            data = data.drop(invalid_cols,axis = 1)\n",
    "            data.index = ['Cell_'+str(x) for x in data.index]\n",
    "            data.columns = [fn.path.split('_')[-1][:-4]+ '_' +x if x not in ['well','DrugName','HMSLid','Conc'] else x for x in data.columns ]\n",
    "            if 'pooled_data' not in globals():\n",
    "                pooled_data = data\n",
    "            else:\n",
    "                pooled_data = pd.concat([pooled_data, data.iloc[:,4:]],axis = 1)\n",
    "    pooled_data, invalid_cells = preprocessing_log_transform(pooled_data)\n",
    "    overall_data = overall_data.append(pooled_data)\n",
    "    del pooled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make distribution plot per channel for each dose of drug\n",
    "# df_logFC = pd.read_excel('MCF10A commons report.xlsx',index_col=0)\n",
    "# df_logFC = df_logFC[df_logFC.Abs_logFC>=0.6]\n",
    "# df_logFC['channel_time'] = df_logFC.index + ':' + df_logFC.Time\n",
    "# df_logFC['drug_channel_time'] = df_logFC.DrugName + df_logFC.index + ':' + df_logFC.Time\n",
    "\n",
    "# overall_data = overall_data.reset_index()\n",
    "# overall_data = overall_data.melt('index',var_name='Channel',  value_name='Log2 Cycif intensity')\n",
    "# overall_data.set_index('index',inplace=True)\n",
    "# overall_data = overall_data.merge(metadata[['DrugName', 'Conc', 'time']], right_index=True, left_index=True, how='left')\n",
    "# overall_data.sort_values('Conc',inplace=True)\n",
    "# overall_data['channel_time'] = overall_data.Channel + ':' + overall_data.time\n",
    "# overall_data['drug_channel_time'] = overall_data.DrugName+overall_data.Channel + ':' + overall_data.time\n",
    "# overall_data = overall_data[overall_data.drug_channel_time.isin(df_logFC.drug_channel_time)]\n",
    "# overall_data.drop(['drug_channel_time','time'],axis = 1, inplace = True)\n",
    "# del df_logFC\n",
    "# overall_data.sort_values('channel_time',inplace = True)\n",
    "\n",
    "for test_drug in metadata.DrugName.unique():\n",
    "    if test_drug == 'DMSO':\n",
    "        continue\n",
    "    df_test = overall_data[overall_data.DrugName.isin([test_drug,'DMSO'])]\n",
    "    sns.set(font_scale=1)\n",
    "    g = sns.FacetGrid(df_test,col='channel_time', hue=\"Conc\", palette=\"RdYlGn_r\",sharey = False ,sharex=False,height = 5,col_wrap=9)\n",
    "    g = (g.map(sns.distplot, \"Log2 Cycif intensity\", hist=False, rug=False))\n",
    "    g.add_legend()\n",
    "    plt.savefig(test_drug + ' abs log FC 0.6 Distribution vs DMSO.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering based per well analysis\n",
    "os.chdir('D:/data/')\n",
    "Report = pd.DataFrame()\n",
    "for time in ['24h','48h','72h']:\n",
    "    for fn in files:\n",
    "        if time in fn.path:\n",
    "            print(fn.path)\n",
    "            data = pd.read_csv(fn.path)\n",
    "            invalid_cols = ['DAPI0002', 'DAPI0003', 'DAPI0004', 'DAPI0005', 'DAPI0006', 'DAPI0007']\n",
    "            data = data.drop(invalid_cols,axis = 1)\n",
    "            data.index = ['Cell_'+str(x) for x in data.index]\n",
    "            metadata = data.iloc[:,:4]\n",
    "            data.columns = [fn.path.split('_')[-1][:-4]+ '_' +x if x not in ['well','DrugName','HMSLid','Conc'] else x for x in data.columns ]\n",
    "            if 'pooled_data' not in globals():\n",
    "                pooled_data = data\n",
    "            else:\n",
    "                pooled_data = pd.concat([pooled_data, data.iloc[:,4:]],axis = 1)\n",
    "            \n",
    "    pooled_data, invalid_cells = preprocessing_log_transform(pooled_data)\n",
    "    metadata.drop(invalid_cells,inplace=True)\n",
    "\n",
    "    # Get control samples that are from the biggest cluster\n",
    "    controls_cells = metadata[metadata.DrugName=='DMSO'].index\n",
    "    control_norm = pooled_data.loc[controls_cells]\n",
    "#     control_norm_umap = umap.fit_transform(control_norm)\n",
    "#     labels = pd.Series(clustering_function.fit_predict(control_norm_umap),index = controls_cells)\n",
    "#     valid_cluster = labels.value_counts().index[0]\n",
    "#     valid_controls = labels[labels==valid_cluster].index\n",
    "#     control_norm = control_norm.loc[valid_controls]\n",
    "#     metadata.loc[labels.index,'Cluster'] = labels.values\n",
    "#     print('From total {} DMSO cells, {} were selected from the biggest cluster'.format(str(len(controls_cells)),str(len(valid_controls))))\n",
    "    # Get markers for each treated condition\n",
    "    metadata['condition'] = metadata.DrugName + '_' + metadata.Conc.round(3).astype(str)\n",
    "    for condition in metadata.condition.unique():\n",
    "        test_cells = metadata[metadata.condition==condition].index\n",
    "        test_dose = condition.split('_')[1]\n",
    "        test_drug = condition.split('_')[0]\n",
    "        test = pooled_data.loc[test_cells]\n",
    "        fig_name = '_'.join([time, test_drug,str(test_dose),'.png'])\n",
    "        \n",
    "        print('Processing: ', time, condition )\n",
    "        DE_report, labels = cluster_based_DE(test,control_norm,fig_name)\n",
    "        # If no DE genes were found, continue\n",
    "        if len(DE_report) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Write DE report\n",
    "        DE_report['Dose'] = test_dose\n",
    "        DE_report['DrugName'] = test_drug\n",
    "        DE_report['Abs_logFC'] = abs(DE_report.logFC)\n",
    "        DE_report['Time'] = time\n",
    "        \n",
    "        # writes clustered cell assignment to file\n",
    "        metadata.loc[labels.index,'Cluster'] = labels.values\n",
    "        \n",
    "        # get top marks per each cluster of each condition if the absolute log2FC is >= 0.6\n",
    "        best_markers = DE_report[DE_report.Abs_logFC>=0.6].index.unique()\n",
    "        Report = Report.append(DE_report)\n",
    "\n",
    "        # making plots\n",
    "        test_plus_norm = test.append(control_norm)\n",
    "        labels = labels.append(pd.Series('control', index = control_norm.index))\n",
    "        test_plus_norm_umap = umap.fit_transform(test_plus_norm)\n",
    "        plot_expr_on_2D(test_plus_norm_umap, test_plus_norm[best_markers],'Expr '+ fig_name, labels)\n",
    "        \n",
    "    # get rid of old pooled_data\n",
    "    del pooled_data\n",
    "    metadata.to_csv(time + ' MCF10A dataset metadata.csv')\n",
    "Report.to_excel('MCF10A commons Per well report.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
