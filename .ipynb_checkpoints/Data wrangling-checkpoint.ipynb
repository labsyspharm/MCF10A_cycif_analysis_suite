{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../../')\n",
    "sys.path.insert(0, '../../cycif/')\n",
    "from common_apis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Z:/sorger/data/IN Cell Analyzer 6000/Connor/Fixed MCF10 Common/20x full exp/20180905_Updated/')\n",
    "plate_info = pd.read_csv('d:/data/MCF10A 090718 data/plate_key.csv',index_col=0)\n",
    "channel_info = pd.read_csv('d:/data/MCF10A 090718 data/channel_key.csv',index_col=0)\n",
    "valid_plates = list(range(1,19))\n",
    "plate_info.index = plate_info.index.astype(str)\n",
    "channel_info.index = channel_info.index.astype(str)\n",
    "print(plate_info.head())\n",
    "print(channel_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame()\n",
    "pooled_data = pd.DataFrame()\n",
    "data_type = 'Mean'\n",
    "for plate in valid_plates:\n",
    "    plate_id = plate\n",
    "    plate = 'Plate' + str(plate)\n",
    "    print(plate)\n",
    "    # Assumes the data was organized by plate and results are in the /analysis folder\n",
    "    path_analysis = os.path.join(plate,'analysis')\n",
    "    indiv_txts = [x for x in os.listdir(path_analysis) if 'txt' in x]\n",
    "    df_plate = pd.DataFrame()\n",
    "    for txt in indiv_txts:\n",
    "        well = txt.split('_')[1]\n",
    "        field = txt.split('_')[2]\n",
    "        fn = os.path.join(path_analysis,txt)\n",
    "        df = pd.read_table(fn)\n",
    "        cols_mean_intensity = [x for x in df.columns if (data_type+'Intensity') in x]\n",
    "        df = df[cols_mean_intensity]\n",
    "        sep = ''.join(['Channel',data_type,'Intensity'])\n",
    "        cols = [x.split(sep )[0] + '_' + channel_info.loc[x.split(sep )[1],'Marker'] for x in df.columns]\n",
    "        df.columns = cols\n",
    "        df['well'] = well\n",
    "        df['field'] = field\n",
    "        df.index = df.apply(lambda x: '_'.join(['cell',x.well,x.field,str(x.name)]),axis = 1)\n",
    "        df_plate = df_plate.append(df)\n",
    "    # QC based on DAPI signalling\n",
    "    lost_cells = []\n",
    "    for i in range(1,8):      \n",
    "        lost_cells += df_plate.index[df_plate.iloc[:,i]<=df_plate.iloc[:,i].quantile(0.03)].tolist()\n",
    "    df_plate.drop(lost_cells,inplace=True)\n",
    "    \n",
    "    plate_id = plate[5:]\n",
    "    plate_metadata = df_plate.merge(plate_info.loc[plate_id],left_on='well',right_on='Well',how='left').loc[:,'well':]\n",
    "    plate_metadata['plate'] = plate_id\n",
    "    metadata = metadata.append(plate_metadata)\n",
    "    pooled_data = pooled_data.append(df_plate)\n",
    "    \n",
    "os.chdir('d:/data/MCF10A 090718 data/')\n",
    "output_preix = ' '.join(['MCF10A 090718 pooled',data_type])\n",
    "metadata.loc[metadata['Concentration (ng/ml)'] == 't0_ctrl','Concentration (ng/ml)'] = 0\n",
    "metadata = metadata.iloc[:,2:]\n",
    "metadata.columns = ['Well','ligand','dose','time','Plate']\n",
    "pooled_bgnd = pd.DataFrame()\n",
    "for i in range(8):\n",
    "    for j in range(9):\n",
    "        if (i==0 or i==4) & (j==2):\n",
    "            break\n",
    "        bgnd = pd.DataFrame(pooled_data.iloc[:,j+9*i]-pooled_data.iloc[:,9*i], columns=[pooled_data.columns[j+9*i]])\n",
    "        pooled_bgnd = pd.concat([pooled_bgnd,bgnd],axis = 1)\n",
    "valid_cols = [x for x in pooled_bgnd.columns if ('bckgrnd' not in x) & ('empty' not in x)]\n",
    "pooled_bgnd = pooled_bgnd[valid_cols]\n",
    "pooled_bgnd[pooled_bgnd<0] = 0\n",
    "pooled_bgnd = np.log2(pooled_bgnd+1)\n",
    "\n",
    "for key,value in {'t0_ctrl':'ctrl','control':'PBS', 'TGFb':'TGFB', 'IFNg':'IFNG'}.items():\n",
    "    metadata.loc[metadata.ligand == key,'ligand'] = value\n",
    "    \n",
    "metadata.Plate = metadata.Plate.astype(int)\n",
    "metadata['condition'] = metadata.ligand + '_' + metadata.time.astype(str)\n",
    "metadata['replicate'] = 'C'\n",
    "metadata.loc[metadata.Plate<=12,'replicate'] = 'B'\n",
    "metadata.loc[metadata.Plate<=6,'replicate'] = 'A'\n",
    "metadata['collection'] = 'C3'\n",
    "metadata['sampleid'] = metadata[['ligand', 'time', 'collection', 'replicate']].astype(str).apply(lambda x: '_'.join(x),axis=1)\n",
    "metadata.to_csv(output_preix+' metadata.csv')\n",
    "pooled_data.iloc[:,:-2].to_csv(output_preix+' raw data.csv')\n",
    "pooled_bgnd.to_csv(output_preix+' normalized data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []\n",
    "for datatype in ['Mean','Median']:\n",
    "    output_preix = ' ' .join(['MCF10A 090718 pooled',datatype])\n",
    "    metadata = pd.read_csv(output_preix+' metadata.csv',index_col=0)\n",
    "    metadata.index = (metadata.Plate.astype(str) + '_' + metadata.index).values\n",
    "    cells.append(metadata.index.tolist())\n",
    "valid_cells = list(set(cells[0])&set(cells[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datatype in ['Mean','Median']:\n",
    "    output_preix = ' '.join(['MCF10A 090718 pooled',datatype])\n",
    "    metadata = pd.read_csv(output_preix+' metadata.csv',index_col=0)\n",
    "    raw_data = pd.read_csv(output_preix+' raw data.csv',index_col=0)\n",
    "    norm_data = pd.read_csv(output_preix+' normalized data.csv',index_col=0)\n",
    "    \n",
    "    for key,value in {'t0_ctrl':'ctrl','control':'PBS', 'TGFb':'TGFB', 'IFNg':'IFNG'}.items():\n",
    "        metadata.loc[metadata.ligand == key,'ligand'] = value\n",
    "    metadata.columns = ['Well', 'ligand', 'dose', 'time', 'Plate', 'condition', 'replicate','collection', 'sampleid']\n",
    "    metadata.Plate = metadata.Plate.astype(int)\n",
    "    metadata['condition'] = metadata.ligand + '_' + metadata.time.astype(str)\n",
    "    metadata['replicate'] = 'C'\n",
    "    metadata.loc[metadata.Plate<=12,'replicate'] = 'B'\n",
    "    metadata.loc[metadata.Plate<=6,'replicate'] = 'A'\n",
    "    metadata['collection'] = 'C3'\n",
    "    metadata['sampleid'] = metadata[['ligand', 'time', 'collection', 'replicate']].astype(str).apply(lambda x: '_'.join(x),axis=1)\n",
    "    \n",
    "    metadata.index = (metadata.Plate.astype(str) + '_' + metadata.index).values\n",
    "    raw_data.index = metadata.index\n",
    "    norm_data.index = metadata.index\n",
    "    filenames = [output_preix+x for x in [' metadata.csv', ' raw data.csv', ' normalized data.csv']]\n",
    "    for df,fn in zip([metadata,raw_data,norm_data], filenames):\n",
    "        df = df[df.index.isin(valid_cells)]\n",
    "        df.to_csv(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
